# é—®é¢˜å¤„ç†æ‰‹å†Œ

## æœªè¯†åˆ«GPUèŠ‚ç‚¹

å®‰è£…TensorFusionåï¼Œå¦‚æœæœªå‘ç°ä»»ä½•GPUèŠ‚ç‚¹ï¼Œè¯·æ£€æŸ¥æ‚¨çš„GPUèŠ‚ç‚¹æ˜¯å¦å·²æ ‡è®°ä¸º `nvidia.com/gpu.present=true`ã€‚

```bash
kubectl get nodes --show-labels | grep nvidia.com/gpu.present=true
```

å¦‚æœæ²¡æœ‰æ ‡è®°ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¿®æ”¹IaCä»£ç ä¸­çš„ `userdata` æˆ–æ‰‹åŠ¨æ·»åŠ æ ‡è®°ã€‚

## TensorFusion OperatoræŒç»­é‡å¯

å¦‚æœTensorFusion operatoræŒç»­é‡å¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å¹¶æŸ¥æ‰¾é”™è¯¯ï¼š

```bash
kubectl logs -n tensor-fusion-sys -l app.kubernetes.io/component=controller
```

å¦‚æœé”™è¯¯æŒ‡ç¤ºä»»ä½•é…ç½®é—®é¢˜ï¼Œè¯·å‚è€ƒTensorFusion Custom Resourceæ–‡æ¡£è¿›è¡Œä¿®å¤ã€‚å¦åˆ™ï¼Œè¯·åœ¨Discordä¸­å¯»æ±‚TensorFusionæ”¯æŒå›¢é˜Ÿçš„å¸®åŠ©ã€‚

## GPU Workeræ— æ³•å·¥ä½œ

å¦‚æœTensorFusion GPU Worker PodæŒç»­é‡å¯ï¼Œæ‚¨å¯ä»¥æ£€æŸ¥æ—¥å¿—ã€‚å¦‚æœæ—¥å¿—ä¿¡æ¯ä¸å¤Ÿè¯¦ç»†ï¼Œè¯·åœ¨TensorFusionClusterè‡ªå®šä¹‰èµ„æºé…ç½®ä¸­çš„worker Podæ¨¡æ¿ä¸­è®¾ç½® `TF_ENABLE_LOG=1`ã€‚

è¯·å°†å´©æºƒæ—¥å¿—å‘é€ç»™TensorFusionæ”¯æŒå›¢é˜Ÿä»¥å¯»æ±‚å¸®åŠ©ã€‚

## "Invalid Memory Address"é—®é¢˜

TensorFusionçš„åº•å±‚è™šæ‹ŸåŒ–æŠ€æœ¯å®ç°äº†é’ˆå¯¹GPUçš„ç‰¹æ®ŠMMIOï¼ŒCUDA `cuMemMap` APIåœ¨æŸäº›æƒ…å†µä¸‹ä¼šå¯¼è‡´å¤æ‚è¡Œä¸ºã€‚ä¸ºæ­¤ï¼ŒTensorFusionå¼€å‘äº†GPUå†…å­˜ç®¡ç†å™¨ï¼Œä½†åœ¨æå°‘æ•°æƒ…å†µä¸‹å¯èƒ½å¯¼è‡´"Invalid Memory Address"é—®é¢˜ã€‚

æ‚¨å¯ä»¥é€šè¿‡ç¦ç”¨å†…å­˜ç®¡ç†å™¨æ¥ç¼“è§£æ­¤é—®é¢˜ã€‚

è¦ç¦ç”¨TensorFusionå†…å­˜ç®¡ç†å™¨ï¼Œè¯·åœ¨é›†ç¾¤é…ç½®ä¸­çš„GPU Worker Podæ¨¡æ¿ä¸­è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
TF_DISABLE_MEMORY_MANAGER=1
```

å¯ç”¨æ­¤é€‰é¡¹åï¼Œå†…å­˜å†»ç»“å’ŒVRAMæ‰©å±•/åˆ†å±‚åŠŸèƒ½å°†æ— æ³•ä½¿ç”¨ã€‚å›¢é˜Ÿå°†ç»§ç»­è‡´åŠ›äºè§£å†³æ­¤é—®é¢˜ã€‚

## é•œåƒæ‹‰å–é—®é¢˜

å¦‚æœK8Sé›†ç¾¤æ— æ³•æ‹‰å–DockerHub, æ£€æŸ¥æ˜¯å¦æ·»åŠ äº†é•œåƒä»“åº“ï¼Œå‚è€ƒ https://docs.k3s.io/installation/private-registry

å¦‚æœæ˜¯K3S + Containerdï¼Œæ£€æŸ¥K3Sæ˜¯å¦æ­£ç¡®åŠ è½½äº†`/etc/rancher/k3s/registries.yaml`æ–‡ä»¶
```bash
# æ­£ç¡®åŠ è½½Mirroråä¼šåœ¨è¿™é‡Œåˆ›å»ºå¯¹åº”hostçš„ç›®å½•
ll /var/lib/rancher/k3s/agent/etc/containerd/certs.d
```

å¦‚æœä»åœ¨ä½¿ç”¨Dockerä½œä¸ºå®¹å™¨äº‘è¿è¡Œæ—¶ï¼Œæ£€æŸ¥Dockeræ˜¯å¦æ­£ç¡®åŠ è½½äº†`/etc/docker/daemon.json`æ–‡ä»¶ï¼Œé‡å¯DockeræœåŠ¡ï¼ˆ`systemctl restart docker`ï¼‰

```json
{
  "registry-mirrors": ["https://docker.m.daocloud.io", "https://docker.1ms.run"]
}
```

å¦‚æœæ˜¯GreptimeDBæ‹‰å–ä¸åˆ°ï¼Œåœ¨helm installæ—¶æ·»åŠ  `--set greptime.image.repository=greptime-registry.cn-hangzhou.cr.aliyuncs.com/greptime/greptimedb`ï¼Œå¦‚æœæ˜¯nvcr.ioç›¸å…³é•œåƒæ‹‰å–ä¸åˆ°ï¼Œå»ºè®®è‡ªè¡ŒåŒæ­¥åˆ°ç§æœ‰ä»“åº“ã€‚


## æ— æ³•ä½¿ç”¨NVIDIAåŸç”Ÿçš„GPUè°ƒåº¦æ–¹å¼ï¼Œæ¯”å¦‚ `nvidia.com/gpu`

å¦‚æœæƒ³è¦ä¿ç•™NVIDIAåŸç”Ÿçš„åŸºäºè®¾å¤‡æ•°é‡çš„è°ƒåº¦æ–¹å¼ï¼Œå¯ä»¥å®‰è£…NVIDIA Device Pluginã€‚

```bash
helm upgrade --install --create-namespace  --namespace nvidia-device-plugin --repo https://nvidia.github.io/k8s-device-plugin/  nvdp nvidia-device-plugin
```


## Pod åœ¨å¯ç”¨ TensorFusion åå¡åœ¨å¯åŠ¨çŠ¶æ€

**å¯èƒ½æœ‰ä¸¤ç§åŸå› ï¼š**

1. æ— å¯ç”¨GPUèµ„æº
2. TensorFusionè¿è¡Œæ—¶åº“æ³¨å…¥å¤±è´¥

å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®šä½æ ¹å› ï¼š`kubectl get po -A --show-labels | grep tensor-fusion.ai/workload`ã€‚è‹¥TensorFusion Worker Podæœªè¿è¡Œï¼Œåˆ™æ˜¯é—®é¢˜1ï¼›å¦åˆ™æ˜¯é—®é¢˜2ã€‚

**å®šä½å’Œè§£å†³é—®é¢˜1** 

æ£€æŸ¥TensorFusionWorkloadè‡ªå®šä¹‰èµ„æºäº‹ä»¶ï¼š`kubectl describe tensorfusionworkload <workload-name>`ã€‚è‹¥å‡ºç°ç±»ä¼¼ `Failed to schedule GPU` çš„é”™è¯¯ï¼Œè¡¨ç¤ºæ²¡æœ‰å¯ç”¨çš„GPUèµ„æºã€‚ç„¶åæ£€æŸ¥ `kubectl get gpu`ï¼Œç¡®è®¤å¯ç”¨èµ„æºæ˜¯å¦å¤§äºè¯·æ±‚çš„è®¡ç®—èµ„æºï¼Œè‹¥èµ„æºä¸è¶³ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯**å‡å°‘å½“å‰åº”ç”¨æˆ–å…¶ä»–åº”ç”¨çš„requestsçš„GPUèµ„æº**ã€‚

è‹¥æ€»TotalTflopsä¸º0æˆ–éƒ¨åˆ†GPUæœªåˆ—å‡ºï¼Œè¡¨ç¤º**TensorFusionæœªå‘ç°æŸäº›GPUå¡**ã€‚è§£å†³æ–¹æ¡ˆæ˜¯æ£€æŸ¥ `kubectl get jobs -n tensor-fusion-sys`ï¼Œç¡®ä¿æ‰€æœ‰NodeDiscovery JobæˆåŠŸï¼Œä¸”`tensor-fusion-sys-public-gpu-info` configMapåŒ…å«æ‚¨çš„GPUå‹å·ï¼Œä¿®æ”¹ååˆ é™¤NodeDiscovery Jobè§¦å‘GPUèµ„æºæ€»é‡çš„è‡ªåŠ¨åˆ·æ–°ã€‚

**å®šä½å’Œè§£å†³é—®é¢˜2**

è‹¥TensorFusion Worker Podæ­£åœ¨è¿è¡Œä¸”çŠ¶æ€ä¸ºReadyï¼Œè¡¨ç¤ºå®¢æˆ·ç«¯æ³¨å…¥å¯èƒ½å¤±è´¥ï¼Œå­˜åœ¨å·²çŸ¥é—®é¢˜ï¼Œå³`LD_PRELOAD`å¯èƒ½è¢«bash/zshå¿½ç•¥ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨`sh -c "bash/zsh ..."`è¿è¡Œbashæˆ–ç›´æ¥ä½¿ç”¨`sh`

ä¾‹å¦‚ï¼Œå½“ä½¿ç”¨ `kubectl exec` æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ `sh -c` å³ä½¿æ‚¨æƒ³ä½¿ç”¨ bash:

```bash
kubectl exec -it <pod> -- sh -c "bash ..."

echo $PATH
# expected result should be:
# /tensor-fusion:/root/.local/bin/:/usr/local/nvidia/bin:...

# then run `nvidia-smi`
# TensorFusion will take effect after PATH/LD_LIBRARY_PATH/LD_PRELOAD contains `/tensor-fusion`
```

å½“æ‚¨çš„åº”ç”¨ç¨‹åºç”±å¦ä¸€ä¸ªè¿›ç¨‹ç”Ÿæˆæ—¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `strace` è¿›è¡Œè°ƒè¯•ã€‚

```bash
# apt/apk/dnf/yum/pacman install strace
strace -e execve -s 99999 <your_program> <your_program_args>
```

## è®¾å¤‡æ•°é‡æ–­è¨€é”™è¯¯

å¦‚æœé‡åˆ°ç±»ä¼¼ä»¥ä¸‹é”™è¯¯ï¼Œè¯´æ˜TensorFusionçš„Clientç«¯æ²¡æœ‰æ­£ç¡®æ³¨å…¥è¿è¡Œæ—¶ç¯å¢ƒï¼Œä¸ğŸ‘†ğŸ»ä¸Šä¸€èŠ‚çš„ç¬¬äºŒä¸ªé—®é¢˜ç›¸åŒ

```
DeferredCudaCallError('CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED 
at "../aten/src/ATen/cuda/CUDAContext.cpp":50, please report a bug to PyTorch.
```

è§£å†³æ–¹æ¡ˆï¼šå¯åœ¨ç¨‹åºå¯åŠ¨æ—¶æ‰“å°`LD_PRELOAD`ã€`LD_LIBRARY_PATH`ã€`PATH` ä¸‰ä¸ªç¯å¢ƒå˜é‡ç¡®è®¤æ˜¯å¦éƒ½å¸¦æœ‰`/tensor-fusion`ï¼Œå¦‚æœæ²¡æœ‰æ³¨å…¥è¯·æ£€æŸ¥å®¹å™¨æ˜¯å¦ç”¨åˆ°äº†ç‰¹æ®Šçš„Entrypointã€Commandå¯åŠ¨ï¼Œå¯¼è‡´ç¯å¢ƒå˜é‡æ²¡æœ‰é€ä¼ ç»™å­è¿›ç¨‹ï¼Œä¹Ÿå¯é€šè¿‡`strace`å‘½ä»¤è¿›è¡Œè°ƒè¯•ã€‚
